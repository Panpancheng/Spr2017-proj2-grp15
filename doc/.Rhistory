<<<<<<< Updated upstream
yloess5 <- loess.wrapper(x, y, span.vals = seq(0.05, 0.5, by = 0.05), folds = 5)
yloess5 <- loess.wrapper(x, y, span.vals = seq(0.25, 1, by = 0.05), folds = 5)
h.optimal <- yloess5$s
h.optimal
plot(x, y, type = "p")
lines(x, yloess5$fitted, type = "l")
plot(x, y, type = "p")
lines(sort(x), fitted(yloess5)[order(x)], type = "l")
curve((1+x)^2 + (2-y)^2 = 4, from = -10, to = 10)
install.packages("glmnet")
library(MASS)
library(glmnet)
train3 <- read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/train_3.txt", header = F)
train5 <- read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/train_5.txt", header = F)
train8 <- read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/train_8.txt", header = F)
test <- read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/zip_test.txt", header = F)
View(test)
names(test) <- c("y", names(test))[1:257]
View(test)
test <- test$y%in%c(3,5,8)
test$y%in%c(3,5,8)
test <- read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/zip_test.txt", header = F)
names(test) <- c("y", names(test))[1:257]
test <- test[test$y%in%c(3,5,8),]
View(train3)
=======
<<<<<<< Updated upstream
=======
<<<<<<< Updated upstream
=======
power.fisher.test(0.8, 0.1, 10, 10, alpha=0.05, nsim=100)
power.fisher.test(0.8, 0.1, 9, 9, alpha=0.05, nsim=100)
power.fisher.test(0.8, 0.1, 9, 9, alpha=0.05/3, nsim=100)
power.fisher.test(0.8, 0.1, 12, 12, alpha=0.05/3, nsim=100)
power.fisher.test(0.8, 0.1, 12, 12, alpha=0.05/4, nsim=100)
power.fisher.test(0.8, 0.1, 12, 12, alpha=0.05/5, nsim=100)
power.fisher.test(0.8, 0.1, 12, 12, alpha=0.05/6, nsim=100)
load("~/Dropbox/Tian_Teaching/G5243-ADS/W5243_ADS-Spr2017/Tutorials/.RData")
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
source("plotstacked.R")
source("speechFuncs.R")
#Economy"         "misc"
#"ItsTheMoment"    "Progress"
#"Election"        "Temporal"
#"Citizens"        "ForeignPolicy"
# "Unity"         "Legislation"
# "Believe"         "Freedom"
# "WorkingFamilies" "Government" "Patriotism"
par(mfrow=c(5, 1), mar=c(1,1,2,0), bty="n", xaxt="n", yaxt="n")
topic.plot=c(1, 13, 14, 15, 8, 9, 12)
print(topics.hash[topic.plot])
speech.df=tbl_df(corpus.list.df)%>%filter(File=="GeorgeBush", type=="nomin",Term==1)%>%select(sent.id, Economy:Patriotism)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="George Bush, Nomination")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="WilliamJClinton", type=="nomin", Term==1)%>%select(sent.id, Economy:Patriotism)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="Bill Clinton, Nomination")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="GeorgeWBush", type=="nomin", Term==1)%>%select(sent.id, Economy:Patriotism)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="George W Bush, Nomination")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="BarackObama", type=="nomin", Term==1)%>%select(sent.id, Economy:Patriotism)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="Barack Obama, Nomination")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="DonaldJTrump", type=="nomin")%>%select(sent.id, Economy:Patriotism)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="Donald Trump, Nomination")
#Economy"         "misc"
#"ItsTheMoment"    "Progress"
#"Election"        "Temporal"
#"Citizens"        "ForeignPolicy"
# "Unity"         "Legislation"
# "Believe"         "Freedom"
# "WorkingFamilies" "Government" "Patriotism"
par(mfrow=c(5, 1), mar=c(1,1,2,0), bty="n", xaxt="n", yaxt="n")
topic.plot=c(1, 13, 14, 15, 8, 9, 12)
print(topics.hash[topic.plot])
speech.df=tbl_df(corpus.list.df)%>%filter(File=="GeorgeBush", type=="nomin",Term==1)%>%select(sent.id, Economy:Patriotism)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="George Bush, Nomination")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="WilliamJClinton", type=="nomin", Term==1)%>%select(sent.id, Economy:Patriotism)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="Bill Clinton, Nomination")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="GeorgeWBush", type=="nomin", Term==1)%>%select(sent.id, Economy:Patriotism)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="George W Bush, Nomination")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="BarackObama", type=="nomin", Term==1)%>%select(sent.id, Economy:Patriotism)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="Barack Obama, Nomination")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="DonaldJTrump", type=="nomin")%>%select(sent.id, Economy:Patriotism)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="Donald Trump, Nomination")
par(mar=c(4, 11, 2, 2))
#sel.comparison=levels(sentence.list$FileOrdered)
sentence.list.sel=filter(sentence.list,
type=="nomin", Term==2, File%in%sel.comparison)
sentence.list.sel$File=factor(sentence.list.sel$File)
sentence.list.sel$FileOrdered=reorder(sentence.list.sel$File,
sentence.list.sel$word.count,
mean,
order=T)
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=2, xlab="Number of words in a sentence.", ylab="",
main="Nomination speeches")
par(mar=c(4, 11, 2, 2))
#sel.comparison=levels(sentence.list$FileOrdered)
sentence.list.sel=filter(sentence.list,
type=="nomin", Term==2, File%in%sel.comparison)
sentence.list.sel$File=factor(sentence.list.sel$File)
sentence.list.sel$FileOrdered=reorder(sentence.list.sel$File,
sentence.list.sel$word.count,
mean,
order=T)
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=2, xlab="Number of words in a sentence.", ylab="",
main="Nomination speeches")
par(mar=c(4, 11, 2, 2))
#sel.comparison=levels(sentence.list$FileOrdered)
sentence.list.sel=filter(sentence.list,
type=="nomin", Term==2, File%in%sel.comparison)
sentence.list.sel$File=factor(sentence.list.sel$File)
sentence.list.sel$FileOrdered=reorder(sentence.list.sel$File,
sentence.list.sel$word.count,
mean,
order=T)
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=2/nlevels(sentence.list.sel$FileOrdered),
las=2, xlab="Number of words in a sentence.", ylab="",
main="Nomination speeches")
par(mar=c(4, 11, 2, 2))
#sel.comparison=levels(sentence.list$FileOrdered)
sentence.list.sel=filter(sentence.list,
type=="nomin", Term==2, File%in%sel.comparison)
sentence.list.sel$File=factor(sentence.list.sel$File)
sentence.list.sel$FileOrdered=reorder(sentence.list.sel$File,
sentence.list.sel$word.count,
mean,
order=T)
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=2/nlevels(sentence.list.sel$FileOrdered),
las=2, xlab="Number of words in a sentence.", ylab="",
main="Nomination speeches, 2nd term")
par(mar=c(4, 11, 2, 2))
#sel.comparison=levels(sentence.list$FileOrdered)
sentence.list.sel=filter(sentence.list,
type=="nomin", Term==2, File%in%sel.comparison)
sentence.list.sel$File=factor(sentence.list.sel$File)
sentence.list.sel$FileOrdered=reorder(sentence.list.sel$File,
sentence.list.sel$word.count,
mean,
order=T)
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
>>>>>>> Stashed changes
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=1.5/nlevels(sentence.list.sel$FileOrdered),
las=2, xlab="Number of words in a sentence.", ylab="",
main="Nomination speeches, 2nd term")
par(mar=c(4, 11, 2, 2))
#sel.comparison=levels(sentence.list$FileOrdered)
sentence.list.sel=filter(sentence.list,
type=="nomin", Term==2, File%in%sel.comparison)
sentence.list.sel$File=factor(sentence.list.sel$File)
sentence.list.sel$FileOrdered=reorder(sentence.list.sel$File,
sentence.list.sel$word.count,
mean,
order=T)
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=1.2/nlevels(sentence.list.sel$FileOrdered),
las=2, xlab="Number of words in a sentence.", ylab="",
main="Nomination speeches, 2nd term")
presid.summary=tbl_df(sentence.list)%>%
filter(type=="nomin", File%in%sel.comparison)%>%
#group_by(paste0(type, File))%>%
group_by(File)%>%
summarise(
anger=mean(anger),
anticipation=mean(anticipation),
disgust=mean(disgust),
fear=mean(fear),
joy=mean(joy),
sadness=mean(sadness),
surprise=mean(surprise),
trust=mean(trust),
#negative=mean(negative),
#positive=mean(positive)
)
sel.comparison=c("DonaldJTrump","JohnMcCain", "GeorgeBush", "MittRomney", "GeorgeWBush",
"RonaldReagan","AlbertGore,Jr", "HillaryClinton","JohnFKerry",
"WilliamJClinton","HarrySTruman", "BarackObama", "LyndonBJohnson",
"GeraldRFord", "JimmyCarter", "DwightDEisenhower", "FranklinDRoosevelt",
"HerbertHoover","JohnFKennedy","RichardNixon","WoodrowWilson",
"AbrahamLincoln", "TheodoreRoosevelt", "JamesGarfield",
"JohnQuincyAdams", "UlyssesSGrant", "ThomasJefferson",
"GeorgeWashington", "WilliamHowardTaft", "AndrewJackson",
"WilliamHenryHarrison", "JohnAdams")
presid.summary=tbl_df(sentence.list)%>%
filter(type=="nomin", File%in%sel.comparison)%>%
#group_by(paste0(type, File))%>%
group_by(File)%>%
summarise(
anger=mean(anger),
anticipation=mean(anticipation),
disgust=mean(disgust),
fear=mean(fear),
joy=mean(joy),
sadness=mean(sadness),
surprise=mean(surprise),
trust=mean(trust),
#negative=mean(negative),
#positive=mean(positive)
)
names(sentence.list)
presid.summary=tbl_df(sentence.list)%>%
filter(type=="nomin", File%in%sel.comparison)%>%
#group_by(paste0(type, File))%>%
group_by(File)%>%
summarise(
anger=mean(anger),
anticipation=mean(anticipation),
disgust=mean(disgust),
fear=mean(fear),
joy=mean(joy),
sadness=mean(sadness),
surprise=mean(surprise),
trust=mean(trust)
#negative=mean(negative),
#positive=mean(positive)
)
presid.summary=as.data.frame(presid.summary)
rownames(presid.summary)=as.character((presid.summary[,1]))
km.res=kmeans(presid.summary[,-1], iter.max=200,
5)
fviz_cluster(km.res,
stand=F, repel= TRUE,
data = presid.summary[,-1], xlab="", xaxt="n",
show.clust.cent=FALSE)
heatmap.2(cor(sentence.list%>%filter(type=="inaug")%>%select(anger:positive)),
scale = "none",
col = bluered(100), , margin=c(6, 6), key=F,
trace = "none", density.info = "none")
par(mar=c(4, 6, 2, 1))
emo.means=colMeans(select(sentence.list, anger:positive)>0.01)
col.use=c("red2", "darkgoldenrod1",
"chartreuse3", "blueviolet",
"darkgoldenrod2", "dodgerblue3",
"darkgoldenrod1", "darkgoldenrod1",
"lightgray", "darkgoldenrod1")
barplot(emo.means[order(emo.means)], las=2, col=col.use[order(emo.means)], horiz=T)
heatmap.2(cor(sentence.list%>%filter(type=="inaug")%>%select(anger:trust)),
scale = "none",
col = bluered(100), , margin=c(6, 6), key=F,
trace = "none", density.info = "none")
par(mar=c(4, 6, 2, 1))
emo.means=colMeans(select(sentence.list, anger:positive)>0.01)
col.use=c("red2", "darkgoldenrod1",
"chartreuse3", "blueviolet",
"darkgoldenrod2", "dodgerblue3",
"darkgoldenrod1", "darkgoldenrod1")
barplot(emo.means[order(emo.means)], las=2, col=col.use[order(emo.means)], horiz=T)
heatmap.2(cor(sentence.list%>%filter(type=="inaug")%>%select(anger:trust)),
scale = "none",
col = bluered(100), , margin=c(6, 6), key=F,
trace = "none", density.info = "none")
par(mar=c(4, 6, 2, 1))
emo.means=colMeans(select(sentence.list, anger:trust)>0.01)
col.use=c("red2", "darkgoldenrod1",
"chartreuse3", "blueviolet",
"darkgoldenrod2", "dodgerblue3",
"darkgoldenrod1", "darkgoldenrod1")
barplot(emo.means[order(emo.means)], las=2, col=col.use[order(emo.means)], horiz=T)
heatmap.2(cor(sentence.list%>%filter(type=="inaug")%>%select(anger:trust)),
scale = "none",
col = bluered(100), , margin=c(6, 6), key=F,
trace = "none", density.info = "none")
par(mar=c(4, 6, 2, 1))
emo.means=colMeans(select(sentence.list, anger:trust)>0.01)
col.use=c("red2", "darkgoldenrod1",
"chartreuse3", "blueviolet",
"darkgoldenrod2", "dodgerblue3",
"darkgoldenrod1", "darkgoldenrod1")
barplot(emo.means[order(emo.means)], las=2, col=col.use[order(emo.means)], horiz=T, main="Inaugural Speeches")
shiny::runApp('Dropbox/Tian_Teaching/G5243-ADS/0-Projects-startercodes/3-Spring2017/Project2_OpenData/app')
runApp('Dropbox/Tian_Teaching/G5243-ADS/0-Projects-startercodes/3-Spring2017/Project2_OpenData/app')
install_version("ggplot2",
version = "2.1.0",
repos = "http://cran.us.r-project.org")
library(devtools)
install_version("ggplot2",
version = "2.1.0",
repos = "http://cran.us.r-project.org")
runApp('Dropbox/Tian_Teaching/G5243-ADS/0-Projects-startercodes/3-Spring2017/Project2_OpenData/app')
runApp('Dropbox/Tian_Teaching/G5243-ADS/0-Projects-startercodes/3-Spring2017/Project2_OpenData/app')
shiny::runApp('Dropbox/Tian_Teaching/G5243-ADS/0-Projects-startercodes/3-Spring2017/Project2_OpenData/app')
library(choroplethrZip)
data(df_pop_zip)
# zooming on a state
zip_choropleth(df_pop_zip,
state_zoom = "new york",
title      = "2012 New York State ZCTA Population Estimates",
legend     = "Population")
install_github('arilamstein/choroplethrZip@v1.4.0')
library(devtools)
install_github('arilamstein/choroplethrZip@v1.4.0')
library(choroplethrZip)
data(df_pop_zip)
# zooming on a state
zip_choropleth(df_pop_zip,
state_zoom = "new york",
title      = "2012 New York State ZCTA Population Estimates",
legend     = "Population")
install.packages("choroplethr")
install.packages("choroplethr")
library(choroplethrZip)
data(df_pop_zip)
# zooming on a state
zip_choropleth(df_pop_zip,
state_zoom = "new york",
title      = "2012 New York State ZCTA Population Estimates",
legend     = "Population")
zip_choropleth
render
c$render
library(choroplethrZip)
zip_choropleth(count.df,
title       = "2009 Manhattan housing sales",
legend      = "Number of sales",
county_zoom = 36061)
if (!require("DT")) install.packages('DT')
if (!require("dtplyr")) install.packages('dtplyr')
if(!require("lubridate")) install.packages('lubridate')
library(dtplyr)
library(dplyr)
library(DT)
library(lubridate)
install.packages("shiny")
library(shiny)
runExample("01_hello")
mh2009=read.csv(file="../data/ManhattanHousing.csv")
datatable(sample_n(mh2009, 50))
mh2009=
mh2009%>%
filter(ZIP.CODE>0)%>%
mutate(region=as.character(ZIP.CODE))
count.df=mh2009%>%
group_by(region)%>%
summarise(
value=n()
)
save(count.df, file="../output/count.RData")
if (!require("choroplethr")) install.packages("choroplethr")
if (!require("devtools")) install.packages("devtools")
library(devtools)
if (!require("choroplethrZip")) install_github('arilamstein/choroplethrZip@v1.4.0')
if (!require("ggplot2")) {
library(devtools)
install_version("ggplot2",
version = "2.1.0",
repos = "http://cran.us.r-project.org")
}
if (!require("ggmap")) install.packages("ggmap")
library(choroplethrZip)
zip_choropleth(count.df,
title       = "2009 Manhattan housing sales",
legend      = "Number of sales",
county_zoom = 36061)
install.packages("ggplot2")
install_github('arilamstein/choroplethrZip@v1.5.0')
library(devtools)
install_github('arilamstein/choroplethrZip@v1.5.0')
install.packages("choroplethr")
install.packages("ggplot2")
install.packages("ggmap")
if (!require("choroplethr")) install.packages("choroplethr")
if (!require("devtools")) install.packages("devtools")
library(devtools)
if (!require("choroplethrZip")) install_github('arilamstein/choroplethrZip@v1.5.0')
if (!require("ggplot2")) {
library(devtools)
install_version("ggplot2",
version = "2.1.0",
repos = "http://cran.us.r-project.org")
}
if (!require("ggmap")) install.packages("ggmap")
library(choroplethrZip)
zip_choropleth(count.df,
title       = "2009 Manhattan housing sales",
legend      = "Number of sales",
county_zoom = 36061)
NYC_map = get_googlemap(center = "New York", maptype = "roadmap",
zoom = 11, size = c(640, 420), color = "bw")
ggmap(NYC_map, extent = "device") +
geom_point(data = mh2009.selgeo, aes(x = lon, y = lat),
color = "#0571b0", size = 3)
ggmap(get_map("New York, New York",zoom=12,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=longitude,y=latitude),  color='red')
library(ggmap)
mh2009.selgeo=
mh2009%>%
sample_n(10)%>%
select(starts_with("ADD"))%>%
mutate(ADDRESS_Ext=paste(ADDRESS, "New York, NY", sep=","))%>%
mutate_geocode(ADDRESS_Ext)
library(ggmap)
library(dplyr)
mh2009.selgeo=
mh2009%>%
sample_n(10)%>%
select(starts_with("ADD"))%>%
mutate(ADDRESS_Ext=paste(ADDRESS, "New York, NY", sep=","))%>%
mutate_geocode(ADDRESS_Ext)
names(mh2009.selgeo)
ggmap(get_map("New York, New York",zoom=12,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=longitude,y=latitude),  color='red')
down vote
I ran into this problem as well today, and I had to install the GitHub development versions of ggplot2 and ggmap and restart R to get rid of this error:
devtools::install_github("dkahle/ggmap")
down vote
I ran into this problem as well today, and I had to install the GitHub development versions of ggplot2 and ggmap and restart R to get rid of this error:
devtools::install_github("dkahle/ggmap")
devtools::install_github("dkahle/ggmap")
devtools::install_github("dkahle/ggmap", force=TRUE)
library(ggmap)
ggmap(get_map("New York, New York",zoom=12,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=longitude,y=latitude),  color='red')
library(ggmap)
ggmap(get_map("New York, New York",zoom=12,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
library(ggmap)
ggmap(get_map("New York, New York",zoom=11,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
library(ggmap)
ggmap(get_map("New York, New York",zoom=9,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
library(ggmap)
ggmap(get_map("New York, New York",zoom=13,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
library(ggmap)
ggmap(get_map("New York, New York",zoom=12,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
library(ggmap)
ggmap(get_map("New York, New York",zoom=11,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
shiny::runApp('~/Dropbox/Tian_Teaching/G5243-ADS/0-Projects-startercodes/3-Spring2017/Project2_OpenData/app')
<<<<<<< Updated upstream
install.packages("DT")
install.packages("lubridate")
install.packages("dtplyr")
install.packages("choroplethrZip")
install.packages("choroplethrZip")
install.packages("devtools")
library(devtools)
install.g
install_github("arilamstein/choroplethrZip@v1.5.0")
install.packages("ggmap")
library(ggmap)
ggmap(get_map("New York, New York",zoom=11,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
library("gplots", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library(ggmap)
ggmap(get_map("New York, New York",zoom=11,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
install_github("dkahle/ggmap")
install_github("hadley/ggplot2")
library(ggmap)
ggmap(get_map("New York, New York",zoom=11,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
library(ggmap)
ggmap(get_map("New York, New York",zoom=11,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
refresh
refresh
.rs.restartR()
library(ggmap)
ggmap(get_map("New York, New York",zoom=11,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
install_github("dkahle/ggmap")
library(devtools)
install_github("dkahle/ggmap")
install_github("hadley/ggplot2")
mh2009.use=
mh2009%>%
mutate(sale.month=month(as.Date(SALE.DATE, "%m/%d/%y")))%>%
>>>>>>> Stashed changes
mutate(sale.price=ifelse(SALE.PRICE==0, NA, SALE.PRICE))%>%
mutate(footage=ifelse(GROSS.SQUARE.FEET==0, NA, GROSS.SQUARE.FEET))%>%
mutate(unit.price=sale.price/footage)%>%
mutate(bldg.type=substr(BUILDING.CLASS.CATEGORY, 1, 2))%>%
filter(bldg.type %in% c("10", "13", "25", "28"))%>%
arrange(bldg.type)
if (!require("DT")) install.packages('DT')
if (!require("dtplyr")) install.packages('dtplyr')
if(!require("lubridate")) install.packages('lubridate')
=======
---
---
title: 'Tutorial 2: EDAV using shiny'
author: "Tian Zheng"
date: "February 3, 2017"
output: ioslides_presentation
---
## Load the data manipulation libraries
```{r load_libs, message=F}
if (!require("DT")) install.packages('DT')
if (!require("dtplyr")) install.packages('dtplyr')
>>>>>>> Stashed changes
library(dtplyr)
library(dplyr)
library(DT)
library(lubridate)
<<<<<<< Updated upstream
library(devtools)
mh2009=read.csv(file="../data/ManhattanHousing.csv")
mh2009=read.csv(file="../data/ManhattanHousing.csv/")
mh2009=read.csv(file="/Users/ouminamikun/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/data/ManhattanHousing.csv")
if (!require("DT")) install.packages('DT')
if (!require("dtplyr")) install.packages('dtplyr')
if(!require("lubridate")) install.packages('lubridate')
library(dtplyr)
library(dplyr)
library(DT)
library(lubridate)
library(devtools)
mh2009=read.csv(file="/Users/ouminamikun/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/data/ManhattanHousing.csv")
datatable(sample_n(mh2009, 50))
mh2009=
mh2009%>%
filter(ZIP.CODE>0)%>%
mutate(region=as.character(ZIP.CODE))
count.df=mh2009%>%
group_by(region)%>%
summarise(
value=n()
)
save(count.df, file="../output/count.RData")
load("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/output/count.RData")
save(count.df, file="/Users/ouminamikun/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/output/count.RData")
if (!require("DT")) install.packages('DT')
if (!require("dtplyr")) install.packages('dtplyr')
if(!require("lubridate")) install.packages('lubridate')
library(dtplyr)
library(dplyr)
library(DT)
library(lubridate)
library(devtools)
mh2009=read.csv(file="/Users/ouminamikun/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/data/ManhattanHousing.csv")
datatable(sample_n(mh2009, 50))
mh2009=
mh2009%>%
filter(ZIP.CODE>0)%>%
mutate(region=as.character(ZIP.CODE))
count.df=mh2009%>%
group_by(region)%>%
summarise(
value=n()
)
save(count.df, file="/Users/ouminamikun/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/output/count.RData")
library(choroplethrZip)
zip_choropleth(count.df,
title       = "2009 Manhattan housing sales",
legend      = "Number of sales",
county_zoom = 36061)
library(ggmap)
library(dplyr)
mh2009.selgeo=
mh2009%>%
sample_n(10)%>%
select(starts_with("ADD"))%>%
mutate(ADDRESS_Ext=paste(ADDRESS, "New York, NY", sep=","))%>%
mutate_geocode(ADDRESS_Ext)
library(ggmap)
ggmap(get_map("New York, New York",zoom=11,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
?datatable
?sample_n
mh2009=
mh2009%>%
filter(ZIP.CODE>0)%>%
mutate(region=as.character(ZIP.CODE))
head
head(mh2009)
mutate()
?mutate
environment(CoorMap$train)
environment(CoordMap$train)
coord_map2()
citation("ggmap")
citation(package = "ggmap")
require(devtools)
install_version("ggplot2", version = "2.6", repos = "http://cran.us.r-project.org")
install_version("ggplot2", version = "2.6.0", repos = "http://cran.us.r-project.org")
install_version("ggplot2", version = "0.9.1", repos = "http://cran.us.r-project.org")
library(ggmap)
install_version("ggplot2", version = "2.2.0", repos = "http://cran.us.r-project.org")
library(ggmap)
ggmap(get_map("New York, New York",zoom=11,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
if (!require("DT")) install.packages('DT')
if (!require("dtplyr")) install.packages('dtplyr')
if(!require("lubridate")) install.packages('lubridate')
library(dtplyr)
library(dplyr)
library(DT)
library(lubridate)
library(devtools)
mh2009=read.csv(file="../data/ManhattanHousing.csv")
datatable(sample_n(mh2009, 50))
mh2009=
mh2009%>%
filter(ZIP.CODE>0)%>%
mutate(region=as.character(ZIP.CODE))
count.df=mh2009%>%
group_by(region)%>%
summarise(
value=n()
)
save(count.df, file="../output/count.RData")
library(choroplethrZip)
zip_choropleth(count.df,
title       = "2009 Manhattan housing sales",
legend      = "Number of sales",
county_zoom = 36061)
library(ggmap)
library(dplyr)
mh2009.selgeo=
mh2009%>%
sample_n(10)%>%
select(starts_with("ADD"))%>%
mutate(ADDRESS_Ext=paste(ADDRESS, "New York, NY", sep=","))%>%
mutate_geocode(ADDRESS_Ext)
library(ggmap)
ggmap(get_map("New York, New York",zoom=11,color = "bw")) +
geom_point(data=mh2009.selgeo, aes(x=lon,y=lat),  color='red')
mh2009.use=
mh2009%>%
mutate(sale.month=month(as.Date(SALE.DATE, "%m/%d/%y")))%>%
mutate(sale.price=ifelse(SALE.PRICE==0, NA, SALE.PRICE))%>%
mutate(footage=ifelse(GROSS.SQUARE.FEET==0, NA, GROSS.SQUARE.FEET))%>%
mutate(unit.price=sale.price/footage)%>%
mutate(bldg.type=substr(BUILDING.CLASS.CATEGORY, 1, 2))%>%
filter(bldg.type %in% c("10", "13", "25", "28"))%>%
arrange(bldg.type)
save(mh2009.use, file="../output/mh2009use.RData")
man.nbhd=c("Central Harlem", "Chelsea and Clinton",
"East Harlem", "Gramercy Park and Murray Hill",
"Greenwich Village and Soho", "Lower Manhattan",
"Lower East Side", "Upper East Side", "Upper West Side",
"Inwood and Washington Heights")
zip.nbhd=list(1:length(man.nbhd))
zip.nbhd[[1]]=c(10026, 10027, 10030, 10037, 10039)
zip.nbhd[[2]]=c(10001, 10011, 10018, 10019, 10020)
zip.nbhd[[3]]=c(10036, 10029, 10035)
zip.nbhd[[4]]=c(10010, 10016, 10017, 10022)
zip.nbhd[[5]]=c(10012, 10013, 10014)
zip.nbhd[[6]]=c(10004, 10005, 10006, 10007, 10038, 10280)
zip.nbhd[[7]]=c(10002, 10003, 10009)
zip.nbhd[[8]]=c(10021, 10028, 10044, 10065, 10075, 10128)
zip.nbhd[[9]]=c(10023, 10024, 10025)
zip.nbhd[[10]]=c(10031, 10032, 10033, 10034, 10040)
shiny::runApp('Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/app')
load("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/output/count.RData")
View(count.df)
runExample("01_hello")
if (!require("DT")) install.packages('DT')
if (!require("dtplyr")) install.packages('dtplyr')
if(!require("lubridate")) install.packages('lubridate')
library(dtplyr)
library(dplyr)
library(DT)
library(lubridate)
library(devtools)
runExample("01_hello")
install.packages("shiny")
library(shiny)
runExample("01_hello")
runApp('~/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/app')
runApp('~/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/app')
runApp('~/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/app')
<<<<<<< Updated upstream
plot(NA, NA, type = "n", xlim = c(-4, 2), ylim = c(-1, 5), asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
plot(NA, NA, type = "n", xlim = c(-4, 2), ylim = c(-1, 5), asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
plot(NA, NA, type = "n", xlim = c(-4, 2), ylim = c(-1, 5), asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
text(c(-1), c(2), "< 4")
text(c(-4), c(2), "> 4")
plot(NA, NA, type = "n", xlim = c(-4, 2), ylim = c(-1, 5), asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
text(c(-1), c(2), "< 4")
text(c(-4), c(2), "> 4")
text(c(4), c(2), ">4")
plot(NA, NA, type = "n", xlim = c(-4, 2), ylim = c(-1, 5), asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
text(c(-1), c(2), "< 4")
text(c(-4), c(2), "> 4")
text(c(2), c(2), ">4")
plot(NA, NA, type = "n", xlim = c(-4, 2), ylim = c(-1, 5), asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
text(c(-1), c(2), "<= 4")
text(c(-4), c(2), "> 4")
text(c(2), c(2), ">4")
plot(c(0, -1, 2, 3), c(0, 1, 2, 8), col = c("blue", "red", "blue", "blue"),
type = "p", xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
plot(c(0, -1, 2, 3), c(0, 1, 2, 8), col = c("blue", "red", "blue", "blue"),
type = "p", asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
plot(c(0, -1, 2, 3), c(0, 1, 2, 8), col = c("blue", "red", "blue", "blue"),
type = "p", asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE)
plot(c(0, -1, 2, 3), c(0, 1, 2, 8), col = c("blue", "red", "blue", "blue"),
type = "p", asp = 1, xlab = "X1", ylab = "X2")
symbols(c(-1), c(2), circles = c(2), add = TRUE, inches = FALSE)
>>>>>>> Stashed changes
library(MASS)
library(glmnet)
train3 <- read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/train_3.txt", header = F,sep = ",")
train5 <- read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/train_5.txt", header = F, sep = ",")
train8 <- read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/train_8.txt", header = F, sep = ",")
test <- read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/zip_test.txt", header = F)
names(test) <- c("y", names(test))[1:257]
test <- test[test$y%in%c(3,5,8),]
d.f <- rbind(train3,train5, train8)
View(d.f)
train3$y <- 3
train5$y <- 5
train8$y <- 8
d.f <- rbind(train3,train5, train8)
View(d.f)
View(d.f)
library(MASS)
library(glmnet)
train3 <- read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/train_3.txt", header = F,sep = ",")
train5 <- read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/train_5.txt", header = F, sep = ",")
train8 <- read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/train_8.txt", header = F, sep = ",")
test <- read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/zip_test.txt", header = F)
names(test) <- c("y", names(test))[1:257]
test <- test[test$y%in%c(3,5,8),]
train3$y <- 3
train5$y <- 5
train8$y <- 8
d.f <- rbind(train3,train5, train8)
View(d.f)
head(d.f)
library(leaps)
lda1 <- lda(y~., data = d.f)
lda1 <- lda(y~., data = d.f)
mat <- (NA, 4,2)
mat <- matrix(NA, 4,2)
mat[1,1]=mean(predict(lad1,d.f)$class == d$y)
lda1 <- lda(y~., data = d.f)
mat <- matrix(NA, 4,2)
mat[1,1]=mean(predict(lda1,d.f)$class == d$y)
mat <- matrix(NA, 4,2)
mat[1,1]=mean(predict(lda1,d.f)$class == d.f$y)
mat[1,2]=mean(predict(lda1,test)$class == test$y)
mat
prc  <- prcomp(d.f[1:256], scale. = T)
std.prc  <- prc$sdev
var.prc <- std.prc^2
prop <- var.prc/sum(var.prc)
plot(prop, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
type = "b")
train.prc <- data.frame(y = d.f$y, prc$x)[,1:50]
lda.prc=lda(y~.,data=train.prc )
mat[2,1]=mean(predict(lad.prc,train.prc)$class == d.f$y)
mat[2,1]=mean(predict(lda.prc,train.prc)$class == d.f$y)
test.pca=as.data.frame(y = test$y,predict(prc, newdata =test[,-1] ))[,1:50]
mat[2,2]=mean(predict(lad.prc,test.prc)$class == test$y)
mat[2,2]=mean(predict(lda.prc,test.prc)$class == test$y)
test.prc=as.data.frame(y = test$y,predict(prc, newdata =test[,-1] ))[,1:50]
mat[2,2]=mean(predict(lda.prc,test.prc)$class == test$y)
mat
d.f.mean <- matrix(NA,dim(d.f)[1], 64)
for( i in 1:dim(d.f)[1])
{
mat2 <- matrix( d.f[i,1:256],16,16,byrow=T)
mat3 <- <- matrix(NA,8,8)
d.f.mean <- matrix(NA,dim(d.f)[1], 64)
for( i in 1:dim(d.f)[1])
{
mat2 <- matrix( d.f[i,1:256],16,16,byrow=T)
mat3 <- matrix(NA,8,8)
for( k in 1:8)
for( t in 1:8)
{
mat3[k,t]=mean(   unlist (mat2[2*k-0:1, 2*t-0:1] )   )
}
d.f.mean[i,]=c(c(mat2))
}
d.mean=matrix(NA,dim(d.f)[1], 64)
for( i in 1:dim(d.f)[1])
{
mat=matrix( d[i,1:256],16,16,byrow=T)
matrix.4=matrix(NA,8,8)
for( k in 1:8)
for( t in 1:8)
{
matrix.4[k,t]=mean(   unlist (mat[2*k-0:1, 2*t-0:1] )   )
}
d.mean[i,]=c(c(matrix.4))
}
d.mean=matrix(NA,dim(d.f)[1], 64)
for( i in 1:dim(d.f)[1])
{
mat=matrix( d.f[i,1:256],16,16,byrow=T)
matrix.4=matrix(NA,8,8)
for( k in 1:8)
for( t in 1:8)
{
matrix.4[k,t]=mean(   unlist (mat[2*k-0:1, 2*t-0:1] )   )
}
d.mean[i,]=c(c(matrix.4))
}
d.mean=data.frame(d.mean)
d.mean$y=d.f$y
test.mean=matrix(NA,dim(test)[1], 64)
for( i in 1:dim(test)[1])
{
mat=matrix( test[i,-1],16,16,byrow=T)
matrix.4=matrix(NA,8,8)
for( k in 1:8)
for( t in 1:8)
{
matrix.4[k,t]=mean(   unlist (mat[2*k-0:1, 2*t-0:1] )   )
}
test.mean[i,]=c(c(matrix.4))
}
test.mean=data.frame(test.mean)
test.mean$y=test$y[i]
lad.4mean=lda(y~.,data=d.mean)
mat[3,1]=mean(predict(lad.4mean,d.mean)$class == d.f$y)
mat[3,2]=mean(predict(lad.4mean,test.mean)$class == test$y)
x_train=as.matrix(d.mean[,1:64])
y_train=factor(d.f$y)
x_test=as.matrix(test.mean[,1:64])
y_test=factor(test$y,levels=levels(y_train))
fit=glmnet(x=x_train,y=y_train,  family="multinomial" )
L=predict(fit,x_train,type="response",s=0.01)[,,1]
predict_train=c()
for(i in 1:dim(L)[1])
predict_train[i]= levels(y_train) [which( L[i,]==max(L[i,]))]
mat[4,1]=mean(predict_train==y_train)
L2=predict(fit,x_test,type="response",s=0.01)[,,1]
predict_test=c()
for(i in 1:dim(L2)[1])
predict_test[i]= levels(y_test) [which( L2[i,]==max(L2[i,])  )]
mat[4,2]=mean(predict_test==y_test)
print(mat)
d3=read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/train_3.txt",header = F,sep=',')
d5=read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/train_5.txt",header = F,sep=',')
library(MASS)
library(glmnet)
d8=read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/train_8.txt",header = F,sep=',')
test=read.table("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ML/HW/Assignment_2/zip_test.txt",header = F)
names(test)=c("y",names(test))[1:257]
test=test[test$y%in%c(3,5,8),]
acc=matrix(NA,4,2)
d3$y=3
d5$y=5
d8$y=8
d=rbind(d3,d5,d8)
lad.full=lda(y~.,data=d)
acc[1,1]=mean(predict(lad.full,d)$class == d$y)
acc[1,2]=mean(predict(lad.full,test)$class == test$y)
prin_comp=prcomp(d[1:256], scale. = T)
std_dev = prin_comp$sdev
pr_var <- std_dev^2
prop_varex <- pr_var/sum(pr_var)
plot(prop_varex, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
type = "b")
train.pca <- data.frame(y = d$y, prin_comp$x)[,1:50]
lad.pca=lda(y~.,data=train.pca )
acc[2,1]=mean(predict(lad.pca,train.pca)$class == d$y)
test.pca=as.data.frame(y = test$y,predict(prin_comp, newdata =test[,-1] ))[,1:50]
acc[2,2]=mean(predict(lad.pca,test.pca)$class == test$y)
d.mean=matrix(NA,dim(d)[1], 64)
for( i in 1:dim(d)[1])
{
mat=matrix( d[i,1:256],16,16,byrow=T)
matrix.4=matrix(NA,8,8)
for( k in 1:8)
for( t in 1:8)
{
matrix.4[k,t]=mean(   unlist (mat[2*k-0:1, 2*t-0:1] )   )
}
d.mean[i,]=c(c(matrix.4))
}
d.mean=data.frame(d.mean)
d.mean$y=d$y
test.mean=matrix(NA,dim(test)[1], 64)
for( i in 1:dim(test)[1])
{
mat=matrix( test[i,-1],16,16,byrow=T)
matrix.4=matrix(NA,8,8)
for( k in 1:8)
for( t in 1:8)
{
matrix.4[k,t]=mean(   unlist (mat[2*k-0:1, 2*t-0:1] )   )
}
test.mean[i,]=c(c(matrix.4))
}
test.mean=data.frame(test.mean)
test.mean$y=test$y[i]
lad.4mean=lda(y~.,data=d.mean)
acc[3,1]=mean(predict(lad.4mean,d.mean)$class == d$y)
acc[3,2]=mean(predict(lad.4mean,test.mean)$class == test$y)
x_train=as.matrix(d.mean[,1:64])
y_train=factor(d$y)
x_test=as.matrix(test.mean[,1:64])
y_test=factor(test$y,levels=levels(y_train))
fit=glmnet(x=x_train,y=y_train,  family="multinomial" )
L=predict(fit,x_train,type="response",s=0.01)[,,1]
predict_train=c()
for(i in 1:dim(L)[1])
predict_train[i]= levels(y_train) [which( L[i,]==max(L[i,]))]
acc[4,1]=mean(predict_train==y_train)
L2=predict(fit,x_test,type="response",s=0.01)[,,1]
predict_test=c()
for(i in 1:dim(L2)[1])
predict_test[i]= levels(y_test) [which( L2[i,]==max(L2[i,])  )]
acc[4,2]=mean(predict_test==y_test)
print(acc)
packages.used=c("tm", "wordcloud", "RColorBrewer",
"dplyr", "tidytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
folder.path="../data/inaugurals/"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
ff.all<-Corpus(DirSource(folder.path))
inspect(ff.all[1])
shools <- list.files(path = "../data/Ranking/", pattern = "*.cvs")
schools
schools <- list.files(path = "../data/Ranking/", pattern = "*.csv")
schools
schools.list <- list.files(path = "../data/Ranking/", pattern = "*.csv")
schools <- lapply(schools.list, read.csv)
schools.list <- paste("..data/Ranking/", schools.list, sep = "")
schools <- lapply(schools.list, read.csv)
crimes <- read.csv("../data/OPE CSS Custom Data 2017-02-12 134856/Criminal_Offenses_On_campus.csv")
for(i in 6:19){
as.numeric(crimes[,i])
}
schools.list <- list.files(path = "../data/Ranking/", pattern = "*.csv")
schools.list <- paste("..data/Ranking/", schools.list, sep = "")
schools <- lapply(schools.list, read.csv)
schools.list <- list.files(path = "../data/Ranking/", pattern = "*.csv")
schools.list <- paste("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/data/Ranking/", schools.list, sep = "")
schools <- lapply(schools.list, read.csv)
schools
class(schools[[1]])
schools
schools.list
schools.list <- list.files(path = "../data/Ranking/", pattern = "*.csv")
schools.list
??getUrls
enrollment <- c(9181, 2209, 12587, 27589, 21679, 6298, 15865, 14769, 17858, 28791, 21372, 11319, 21554, 8808, 6621, 16963, 10907, 37565, 41845, 15097,43625, 29135, 12179, 24806, 42453, 23732, 12686, 7788, 14348, 12336)
length(enrollment)
for(i in 1:30){
schools[[i]]$enrollment <- enrollment[i]
}
head(schools)
head(schools[[1]])
##read in all universities files
schools.list <- list.files(path = "../data/Ranking/", pattern = "*.csv")
schools.list <- paste("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/data/Ranking/", schools.list, sep = "")
schools <- lapply(schools.list, read.csv)
years
years <- as.integer(2001:2014)
years
crimes <- read.csv("../data/OPE CSS Custom Data 2017-02-12 134856/Criminal_Offenses_On_campus.csv")
for(i in 6:19){
as.numeric(crimes[,i])
}
##calculate total crimes for every year
crimes$total <- rowSums(crimes[,-c(1:6)],na.rm = TRUE)
crimes.split <- split(crimes, f = as.factor(crimes$Survey.year))
year.sum <- NA
for(i in 1: length(crimes.split)){
year.sum[i] <- sum(crimes.split[[i]]$total)
}
#calculate every type of crimes for every year
agg <- aggregate(crimes[,-c(1:6)], list(crimes$Survey.year), sum)
View(agg)
mat <- matrix(NA)
for(i in 1:30){
for(j in 1:14){
boolean <- schools[[i]]$Survey.year == years[j]
mat[j,i+1] <- colSums(schools[[i]][boolean,][,-c(1:6)])
}
}
for(i in 30){
schools[[i]]$total <- rowsum(schools[[i]][,-c(1:6)])
}
for(i in 30){
schools[[i]]$total <- rowSums(schools[[i]][,-c(1:6)], na.rm = T)
}
head(schools[[1]])
##read in all universities files
schools.list <- list.files(path = "../data/Ranking/", pattern = "*.csv")
schools.list <- paste("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/data/Ranking/", schools.list, sep = "")
schools <- lapply(schools.list, read.csv)
years <- as.integer(2001:2014)
for(i in 30){
schools[[i]]$total <- rowSums(schools[[i]][,-c(1:6)], na.rm = T)
}
head(schools[[1]])
rowSums(schools[[1]][,-c(1:6)])
rowSums(schools[[1]][,-c(1:6)], na.rm = T)
for(i in 30){
schools[[i]]$total <- rowSums(schools[[i]][,-c(1:6)], na.rm = T)
}
schools[[1]]$Arson
schools[[1]]$total <- rowSums(schools[[1]][,-c(1:6)], na.rm = T)
schools[[1]]$total
head(schools[[1]])
head(schools[[2]])
datatable(sample_n(crimes, 50))
??datatable
library(DT)
datatable(sample_n(crimes, 50))
library(shiny)
?runExample
runExample("01_hello")
?selectInput
data.frame(schools)
schools <- sapply(schools.list, read.csv)
head(schools)
View(schools)
library(plyr)
schools <- ddply(schools.list, read.csv)
schools.list <- list.files(path = "../data/Ranking/", pattern = "*.csv")
schools.list <- paste("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/data/Ranking/", schools.list, sep = "")
schools <- ddply(schools.list, read.csv)
schools <- lapply(schools.list, read.csv)
ldply(schools)
d.schools <- ldply(schools)
head
head(d.schools)
agg1 <- aggregate(d.schools[,-c(1:6)], list(d.schools$Survey.year, d.schools$Institution.name), rowSums)
agg1 <- aggregate(d.schools[,-c(1:6)], list(d.schools$Survey.year, d.schools$Institution.name), sum)
View(agg)
View(agg1)
for(i in 1:30){
schools[[i]]$total <- rowSums(schools[[i]][,-c(1:6)], na.rm = T)
}
head(schools[[1]])
View(d.schools)
agg1 <- aggregate(d.schools[,-c(1:6)], list(d.schools$Survey.year, d.schools$Institution.name, d.schools[,-c(1:6)]), colSums)
View(agg1)
agg1 <- aggregate(d.schools[,-c(1:6)], list(d.schools$Survey.year, d.schools$Institution.name, sum)
years <- as.integer(2001:2014)
agg1 <- aggregate(d.schools[,-c(1:6)], list(d.schools$Survey.year, d.schools$Institution.name, sum))
agg1 <- aggregate(d.schools[,-c(1:6)], list(d.schools$Survey.year, d.schools$Institution.name), sum)
View(agg1)
View(agg1)
for(i in 1:30){
schools[[i]]$total <- rowSums(schools[[i]][,-c(1:6)], na.rm = T)
}
d.shcools <- ldply(schools)
#calulate the num of every type of crime for each institution every year
agg1 <- aggregate(d.schools[,-c(1:6)], list(d.schools$Survey.year, d.schools$Institution.name), sum)
View(agg1)
names(col(d.schools))
colnames(d.schools)
colnames(d.shcools)
##read in all universities files
schools.list <- list.files(path = "../data/Ranking/", pattern = "*.csv")
schools.list <- paste("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/data/Ranking/", schools.list, sep = "")
schools <- lapply(schools.list, read.csv)
#calculate total crimes for each campus
for(i in 1:30){
schools[[i]]$total <- rowSums(schools[[i]][,-c(1:6)], na.rm = T)
}
d.shcools <- ldply(schools)
#calulate the num of every type of crime for each institution every year
agg1 <- aggregate(d.schools[,-c(1:6)], list(d.schools$Survey.year, d.schools$Institution.name), sum)
d.schools <- ldply(schools)
agg1 <- aggregate(d.schools[,-c(1:6)], list(d.schools$Survey.year, d.schools$Institution.name), sum)
View(agg1)
library(shiny)
ui <- fluidPage(
titlePanel("Compare Data for Two Schools"),
fluidRow(style = "padding-bottom: 20px;",
column(4, selectInput('school1', 'School 1',
schools.list,
selected=schools.list[1])),
column(4, selectInput('school2', 'School 2', schools.list,
selected=schools.list[9]))
),
fluidRow(
plotOutput('trend', height = "400px")
)
)
shinyApp(ui = ui)
shinyApp(ui = ui, server = NULL)
View(agg1)
enrollment
enrollment1 <- rep(enrollment, 14)
head(enrollment)
aggregate(d.schools$Institution.Size, list(d.schools$Survey.year))
dim(schools)
dim(d.schools)
for(i in 1:dim(d.schools)[1]){
enrollment <- rep(enrollment[i], 14)
}
head(enrollment)
enrollment <- c(9181, 2209, 12587, 27589, 21679, 6298, 15865, 14769, 17858, 28791, 21372, 11319, 21554  ,8808, 6621, 16963,10907, 37565, 41845, 15097, 43625, 29135, 12179, 24806, 42453, 23732, 12686, 7788, 14348, 12336)
sapply(enrollment, rep, 14)
length(years)
enrollment <- as.vector(sapply(enrollment, rep, 14))
enrollment
agg1$institution.size <- enrollment
View(agg1)
library(DT)
library(plyr)
crimes <- read.csv("../data/OPE CSS Custom Data 2017-02-12 134856/Criminal_Offenses_On_campus.csv")
for(i in 6:19){
as.numeric(crimes[,i])
}
datatable(sample_n(crimes, 50))
##calculate total num of crimes for every year
crimes$total <- rowSums(crimes[,-c(1:6)],na.rm = TRUE)
crimes.split <- split(crimes, f = as.factor(crimes$Survey.year))
year.sum <- NA
for(i in 1: length(crimes.split)){
year.sum[i] <- sum(crimes.split[[i]]$total)
}
#calculate num of every type of crimes for every year
agg <- aggregate(crimes[,-c(1:6)], list(crimes$Survey.year), sum)
<<<<<<< Updated upstream
##read in all universities files
schools.list <- list.files(path = "../data/Ranking/", pattern = "*.csv")
schools.list <- paste("/Users/ouminamikun/Desktop/Columbia/Spring 2017/ADS/Spr2017-proj2-grp15/data/Ranking/", schools.list, sep = "")
schools <- lapply(schools.list, read.csv)
#calculate total crimes for each campus
for(i in 1:30){
schools[[i]]$total <- rowSums(schools[[i]][,-c(1:6)], na.rm = T)
}
#calulate the num of every type of crime for each institution every year
d.schools <- ldply(schools)
agg1 <- aggregate(d.schools[,-c(1:6)], list(d.schools$Survey.year, d.schools$Institution.name), sum)
enrollment <- c(9181, 2209, 12587, 27589, 21679, 6298, 15865, 14769, 17858, 28791, 21372, 11319, 21554  ,8808, 6621, 16963,10907, 37565, 41845, 15097, 43625, 29135, 12179, 24806, 42453, 23732, 12686, 7788, 14348, 12336)
enrollment <- as.vector(sapply(enrollment, rep, 14))
agg1$institution.size <- enrollment
schools2014 <- d.schools[d.shcools$Survey.year == "2014",]
View(schools2014)
?sample_n
table <- datatable(sample_n(schools2014))
table <- datatable(sample_n(schools2014, 50))
table
View(agg1)
schools2014 <- agg1[agg1$Group.1 == "2014",]
table <- datatable(sample_n(schools2014, 50))
table <- datatable(sample_n(schools2014, 30))
table
View(schools2014)
?dataTableOutput
library(shiny)
library(ggplot2)
ui <- fluidPage(
titlePanel("Compare Data for Two Schools"),
# Create a new Row in the UI for selectInputs
fluidRow(
column(4,
selectInput("school",
"School:",
c("All",
unique(as.character(schools2014$Group.2))))
)
),
# Create a new row for the table.
fluidRow(
DT::dataTableOutput("table")
)
)
server <- function(input, output) {
# Filter data based on selections
output$table <- DT::renderDataTable(DT::datatable({
data <- schools2014
if (input$school != "All") {
data <- data[data$Group.2 == input$school,]
}
data
}))
}
shinyApp(ui = ui, server = server)
=======
View(crimes)
crimes[,crimes$Institution.name == "Purdue University"]
=======
=======
```
## Install shiny
```{r install_shiny, eval=F}
install.packages("shiny")
library(shiny)
runExample("01_hello")
>>>>>>> Stashed changes
>>>>>>> Stashed changes
>>>>>>> Stashed changes
